{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab8 (PART 2)\n",
    "Name: Birva Babaria || Rollno: CE010 || ID: 19CEUON064"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Try this on full spam2.csv file and bigram matching instead of unigram matching***\n",
    "\n",
    "##### ***Spam classification using Count Vectorization and TFIDf Vectorization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\",\n",
    "\"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\",\n",
    "\"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\",\n",
    "\"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\",\n",
    "\"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
    "\"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\",\n",
    "\"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\",\n",
    "\"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\",\n",
    "\"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\",\n",
    "\"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\",\n",
    "\"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\",\n",
    "\"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\",\n",
    "\"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\",\n",
    "\"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\",\n",
    "\"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "\"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\",\n",
    "\"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\",\n",
    "\"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data :\n",
      "     v1                                                 v2\n",
      "0    0  Go until jurong point, crazy.. Available only ...\n",
      "1    0                      Ok lar... Joking wif u oni...\n",
      "2    1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    0  U dun say so early hor... U c already then say...\n",
      "4    0  Nah I don't think he goes to usf, he lives aro...\n",
      "5    1  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    0  Even my brother is not like to speak with me. ...\n",
      "7    0  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    1  WINNER!! As a valued network customer you have...\n",
      "9    1  Had your mobile 11 months or more? U R entitle...\n",
      "10   0  I'm gonna be home soon and i don't want to tal...\n",
      "11   1  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12   1  URGENT! You have won a 1 week FREE membership ...\n",
      "13   0  I've been searching for the right words to tha...\n",
      "14   0                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15   1  XXXMobileMovieClub: To use your credit, click ...\n",
      "16   0                         Oh k...i'm watching here:)\n",
      "17   0  Eh u remember how 2 spell his name... Yes i di...\n",
      "18   0  Fine if thatï¿½ï¿½s the way u feel. Thatï¿½ï¿½...\n",
      "19   1  England v Macedonia - dont miss the goals/team...\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "datasets = pd.read_csv('spam2.csv', encoding=\"ISO-8859-1\")\n",
    "datasets[\"v1\"]=np.where(datasets[\"v1\"]=='spam',1,0)\n",
    "print(\"\\nData :\\n\",datasets.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(datasets[\"v2\"], datasets[\"v1\"],random_state=175)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***CountVectorizer (Perform count vectorization on training data.)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let', 'll', 're', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (2, 2),stop_words=stopwords)\n",
    "vectorizer.fit(X_train)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "# print(vectorizer.get_feature_names())\n",
    "print(X_train_vectorized.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "model=MultinomialNB()\n",
    "model.fit(X_train_vectorized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9834888729361091\n",
      "\n",
      "Precision:  0.9935064935064936\n",
      "\n",
      "Recall:  0.8742857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "predictions = model.predict(vectorizer.transform(X_test))\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
    "print(\"\\nPrecision: \", precision_score(y_test, predictions))\n",
    "print(\"\\nRecall: \", recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Apply the Decision Tree Classifier on vectorized data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9712849964106246\n",
      "\n",
      "Precision:  0.9787234042553191\n",
      "\n",
      "Recall:  0.7885714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "predictions = clf.predict(vectorizer.transform(X_test))\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
    "print(\"\\nPrecision: \", precision_score(y_test, predictions))\n",
    "print(\"\\nRecall: \", recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***TFIDF Vectorizer (Perform IFIDF vectorization on training data.)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let', 'll', 're', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (2, 2),stop_words = stopwords)\n",
    "vectorizer.fit(X_train)\n",
    "X_train_tfidf_vectorized = vectorizer.transform(X_train)\n",
    "print(X_train_tfidf_vectorized.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Apply the Naive Bayes on IFIDF vectorized data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9540559942569993\n",
      "\n",
      "Precision:  1.0\n",
      "\n",
      "Recall:  0.6342857142857142\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(vectorizer.transform(X_test))\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
    "print(\"\\nPrecision: \", precision_score(y_test, predictions))\n",
    "print(\"\\nRecall: \", recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Apply the Decision Tree Classifier on IFIDF vectorized data.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train_tfidf_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9662598707824839\n",
      "\n",
      "Precision:  0.9705882352941176\n",
      "\n",
      "Recall:  0.7542857142857143\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(vectorizer.transform(X_test))\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
    "print(\"\\nPrecision: \", precision_score(y_test, predictions))\n",
    "print(\"\\nRecall: \", recall_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
